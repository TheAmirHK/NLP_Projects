{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw9waBqMYJ6WwSQ4ZXcGe8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheAmirHK/NLP_Projects/blob/Book_reviewer/Worth_a_Read_(NLP)_based_on_Goodreads_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python script uses Selenium to scrape reviews and extract them from a Goodreads book page. Finally it teturns a list of reviews.\n"
      ],
      "metadata": {
        "id": "e5_e3JRPRYEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!pip install google-colab-selenium\n",
        "!pip install sumy"
      ],
      "metadata": {
        "id": "cPH4PBmZymRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google_colab_selenium as gs\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium import webdriver\n",
        "import time\n",
        "\n",
        "from selenium import webdriver"
      ],
      "metadata": {
        "id": "3lSZoosB0rjA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_goodreads_reviews_selenium(book_url, num_reviews=10):\n",
        "    reviews = []\n",
        "    try:\n",
        "        # Setup Selenium WebDriver (ensure you have the correct path to the ChromeDriver)\n",
        "        driver = gs.Chrome()\n",
        "\n",
        "        driver.get(book_url)\n",
        "        reviews.append(driver.title)\n",
        "\n",
        "        # Wait for the reviews to load (adjust if necessary)\n",
        "        time.sleep(2)\n",
        "\n",
        "        scroll_pause_time = 1 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
        "        screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
        "        i = 1\n",
        "\n",
        "        while True:\n",
        "            # scroll one screen height each time\n",
        "            driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))\n",
        "            i += 1\n",
        "            time.sleep(scroll_pause_time)\n",
        "            # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
        "            scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
        "            # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
        "            if (screen_height) * i > scroll_height:\n",
        "                break\n",
        "\n",
        "        # Extract review text\n",
        "        review_elements = driver.find_elements(By.CLASS_NAME, 'ReviewText')\n",
        "        for review in review_elements[:num_reviews]:\n",
        "            reviews.append(review.text)\n",
        "\n",
        "        driver.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error while scraping: {e}\")\n",
        "    return reviews\n",
        "\n",
        "# Example Goodreads book URL\n",
        "book_url = \"https://www.goodreads.com/book/show/60194162/reviews?reviewFilters=eyJhZnRlciI6Ik1UTTRNVFVzTVRZMk56WTRNak15TURreE5nIn0%3D\"  # Update with a valid URL\n",
        "reviews = scrape_goodreads_reviews_selenium(book_url, num_reviews=50)\n",
        "actualTitle = reviews[0].split(\" book reviews \")[0]\n",
        "\n",
        "# Print the reviews\n",
        "print(f\"Scraped {len(reviews)} reviews:\")\n",
        "for i, review in enumerate(reviews, 1):\n",
        "    print(f\"{i}: {review}\")\n"
      ],
      "metadata": {
        "id": "DV43i-0FykOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def summarize_reviews(reviews, num_sentences=5):\n",
        "    # Join all reviews into one string\n",
        "    reviews_text = \" \".join(reviews)\n",
        "\n",
        "    try:\n",
        "        parser = PlaintextParser.from_string(reviews_text, Tokenizer(\"english\"))\n",
        "        summarizer = LsaSummarizer()\n",
        "        summary_sentences = summarizer(parser.document, 5)\n",
        "        summary = \" \".join(str(sentence) for sentence in summary_sentences)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error summarizing text: {str(e)}\"\n",
        "\n",
        "summary = summarize_reviews(reviews)\n",
        "print(\"Summary of Reviews:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "YHZZnti3VYW4",
        "outputId": "b8c29a15-f566-4d3a-894c-658f4ec3d7a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Reviews:\n",
            "Kingsolver has created a very particular world, inhabited it with people you can’t forget, and coerced from me an emotional investment that I’m not often willing to make in fiction. You can talk about substance abuse, poverty, domestic violence, assault, the foster care system, and ineffective social services without turning an already misrepresented population into sideshow freaks. Narrated entirely by Demon – his strength of character, enduring, resilience spirit, and ability to find humour in any situation that was thrown at him, made this an unforgettable read. Show more Tragic and heartbreaking The story takes place mostly in southern Appalachian Lee County, Virginia where Demon (Damon) was born to a teen mother with addiction. Show more Update: This book did win Kingsolver her long-awaited Pulitzer (along with Hernan Diaz’s Trust) so, for the first time, I made a good guess :-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join(text.split())  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Preprocess scraped reviews\n",
        "preprocessed_reviews = [preprocess_text(review) for review in reviews]"
      ],
      "metadata": {
        "id": "Bj0xb5hZWMUX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_reviews(reviews):\n",
        "    labels = []\n",
        "    positive_keywords = [\n",
        "    \"exciting\", \"gripping\", \"captivating\", \"engaging\", \"amazing\", \"brilliant\", \"wonderful\",\n",
        "    \"fantastic\", \"unforgettable\", \"well-written\", \"masterpiece\", \"incredible\", \"thrilling\",\n",
        "    \"impressive\", \"heartwarming\", \"thought-provoking\", \"enjoyable\", \"powerful\", \"compelling\",\n",
        "    \"beautiful\", \"breathtaking\", \"page-turner\", \"intriguing\", \"spellbinding\", \"inspirational\",\n",
        "    \"charming\", \"unpredictable\", \"vivid\", \"well-paced\", \"moving\", \"creative\", \"emotional\",\n",
        "    \"excels\", \"flawless\", \"richly detailed\", \"uplifting\", \"poignant\", \"immersive\", \"thoughtful\",\n",
        "    \"enlightening\"\n",
        "]\n",
        "    negative_keywords = [\n",
        "    \"boring\", \"predictable\", \"disappointing\", \"poorly written\", \"unimpressive\", \"slow\",\n",
        "    \"terrible\", \"awful\", \"weak\", \"unoriginal\", \"confusing\", \"lackluster\", \"dragging\",\n",
        "    \"forgettable\", \"frustrating\", \"painful\", \"underwhelming\", \"monotonous\", \"dull\",\n",
        "    \"disconnected\", \"unrealistic\", \"shallow\", \"predictable\", \"lack of depth\", \"unengaging\",\n",
        "    \"unconvincing\", \"clunky\", \"uninteresting\", \"overrated\", \"unpleasant\", \"bland\", \"empty\",\n",
        "    \"tedious\", \"badly paced\", \"unstructured\", \"uncompelling\", \"incoherent\", \"unsatisfying\",\n",
        "    \"frivolous\", \"mediocre\", \"disjointed\", \"unmemorable\", \"unfocused\", \"poor\"\n",
        "]\n",
        "\n",
        "    for review in reviews:\n",
        "        if any(word in review.lower() for word in positive_keywords):\n",
        "            labels.append(\"Positive\")  # Positive\n",
        "        elif any(word in review.lower() for word in negative_keywords):\n",
        "            labels.append(\"Negative\")  # Negative\n",
        "        else:\n",
        "            labels.append(None)  # Neutral/No clear sentiment\n",
        "    return labels\n",
        "\n",
        "# Label the preprocessed reviews\n",
        "labels = label_reviews(reviews)\n",
        "\n",
        "# Filter out neutral reviews\n",
        "labeled_data = [(reviews[i], labels[i]) for i in range(len(labels)) if labels[i] is not None]\n",
        "texts, sentiments = zip(*labeled_data)"
      ],
      "metadata": {
        "id": "IqL5Lk8MTUA3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Convert text into numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, sentiments, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IyQJ3R3Vy4v",
        "outputId": "7b1d0bd6-c05a-4bb5-a2bf-2f4be6254c15"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.00      0.00      0.00         1\n",
            "    Positive       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.42      0.50      0.45         6\n",
            "weighted avg       0.69      0.83      0.76         6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_movie_reviews(reviews, model, vectorizer):\n",
        "    preprocessed_reviews = [preprocess_text(review) for review in reviews]\n",
        "    features = vectorizer.transform(preprocessed_reviews)\n",
        "    predictions = model.predict(features)\n",
        "    positive_count = predictions.tolist().count('Positive')\n",
        "\n",
        "    return positive_count / len(predictions) * 100 # Calculate and return percentage\n",
        "\n",
        "# Analyze the movie based on positive review percentage\n",
        "positive_percentage = analyze_movie_reviews(reviews, model, vectorizer)\n",
        "# print(f\"Percentage of positive reviews: {positive_percentage:.2f}%\")\n",
        "if positive_percentage > 70:\n",
        "    print(f\"The book {actualTitle} is likely WORTH {positive_percentage:.0f}% reading !\")\n",
        "else:\n",
        "    print(f\"The book {actualTitle} is likely NOT worth reading.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5xY1VLBV-UP",
        "outputId": "1ddd9e0c-d002-4835-b143-605327586b05"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The book Demon Copperhead by Barbara Kingsolver is likely WORTH 100% reading !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auDGvppCTUqR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def summarize_reviews(reviews, num_sentences=5):\n",
        "    # Join all reviews into one string\n",
        "    reviews_text = \" \".join(reviews)\n",
        "\n",
        "    try:\n",
        "        parser = PlaintextParser.from_string(reviews_text, Tokenizer(\"english\"))\n",
        "        summarizer = LsaSummarizer()\n",
        "        summary_sentences = summarizer(parser.document, 5)\n",
        "        summary = \" \".join(str(sentence) for sentence in summary_sentences)\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error summarizing text: {str(e)}\"\n",
        "\n",
        "summary = summarize_reviews(reviews)\n",
        "print(\"Summary of Reviews:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "CermJRAORxf_",
        "outputId": "54f2a122-4714-45f3-fe9a-5011b24cc519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Reviews:\n",
            "Kingsolver has created a very particular world, inhabited it with people you can’t forget, and coerced from me an emotional investment that I’m not often willing to make in fiction. You can talk about substance abuse, poverty, domestic violence, assault, the foster care system, and ineffective social services without turning an already misrepresented population into sideshow freaks. Narrated entirely by Demon – his strength of character, enduring, resilience spirit, and ability to find humour in any situation that was thrown at him, made this an unforgettable read. Show more Tragic and heartbreaking The story takes place mostly in southern Appalachian Lee County, Virginia where Demon (Damon) was born to a teen mother with addiction. Show more Update: This book did win Kingsolver her long-awaited Pulitzer (along with Hernan Diaz’s Trust) so, for the first time, I made a good guess :-)\n"
          ]
        }
      ]
    }
  ]
}